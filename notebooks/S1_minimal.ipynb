{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad99b75e",
   "metadata": {
    "id": "ad99b75e"
   },
   "source": [
    "# S1 — Minimal: Dense → Masked → CSR\n",
    "Simple, readable baseline with robust perplexity and measured sparsity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ILE-ENu_uJv_",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ILE-ENu_uJv_",
    "outputId": "09437689-a501-4797-9570-5d3a1a556294"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/Edu-Sparsify-LLMs/notebooks\n"
     ]
    }
   ],
   "source": [
    "#For Google Colab\n",
    "%cd /content/Edu-Sparsify-LLMs/notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4785b8cd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4785b8cd",
    "outputId": "7bf36799-2947-4638-94b4-20305a86b56b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os, sys, warnings, pandas as pd, torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "sys.path.append('..'); sys.path.append('../src')\n",
    "from src.eval.metrics import params_size_and_sparsity, eval_ppl_causal\n",
    "from src.eval.utils import measure_latency_ms\n",
    "from src.eval.csvlog import append_row\n",
    "from src.eval.plotting import bar_plot\n",
    "from src.pruning.policies import apply_global_magnitude_pruning_cpu_safe, select_prunable_linears\n",
    "from src.pruning.pipeline import freeze_pruning_, convert_linear_weights_to_csr_\n",
    "from src.wrappers.linear_csr import LinearCSRForward\n",
    "warnings.filterwarnings('ignore', message='.*Sparse CSR tensor support is in beta state.*')\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Device:', device)\n",
    "RESULTS_DIR = os.path.join('..','results'); CSV_PATH = os.path.join(RESULTS_DIR,'S1_minimal.csv')\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "pd.DataFrame(columns=[\"setup\",\"size_mb\",\"sparsity\",\"latency_ms\",\"perplexity\"]).to_csv(CSV_PATH, index=False)\n",
    "\n",
    "def load_fresh():\n",
    "    \"\"\"\n",
    "    Load exactly one model depending on the device:\n",
    "      - CUDA  -> EleutherAI/pythia-410m (fp16)\n",
    "      - CPU   -> facebook/opt-125m     (fp32)\n",
    "    \"\"\"\n",
    "    if device == \"cuda\":\n",
    "        model_name = \"EleutherAI/pythia-410m\"\n",
    "        torch_dtype = torch.float16\n",
    "    else:\n",
    "        model_name = \"facebook/opt-125m\"\n",
    "        torch_dtype = None  # use default (fp32)\n",
    "    tok = AutoTokenizer.from_pretrained(model_name)\n",
    "    tok.pad_token = tok.eos_token\n",
    "    kwargs = {}\n",
    "    if torch_dtype is not None:\n",
    "        kwargs[\"torch_dtype\"] = torch_dtype\n",
    "    mdl = AutoModelForCausalLM.from_pretrained(model_name, **kwargs).to(device).eval()\n",
    "    print(f\"Loaded: {model_name}\")\n",
    "    return mdl, tok, model_name\n",
    "\n",
    "def latency_fn(model, tokenizer, gen_tokens=64):\n",
    "    def f(L=128, B=1):\n",
    "        inp = torch.randint(0, tokenizer.vocab_size, (B, L), device=device)\n",
    "        att = torch.ones(B, L, device=device, dtype=torch.long)\n",
    "\n",
    "        # Sécurité: pad/eos pour generate\n",
    "        pad_id = tokenizer.pad_token_id if tokenizer.pad_token_id is not None else tokenizer.eos_token_id\n",
    "        eos_id = tokenizer.eos_token_id\n",
    "\n",
    "        with torch.inference_mode():\n",
    "            _ = model.generate(\n",
    "                input_ids=inp,\n",
    "                attention_mask=att,\n",
    "                max_new_tokens=gen_tokens,\n",
    "                do_sample=False,\n",
    "                use_cache=True,\n",
    "                pad_token_id=pad_id,\n",
    "                eos_token_id=eos_id\n",
    "            )\n",
    "        # measure_latency_ms attend juste que f(L,B) \"fasse le travail\"\n",
    "        return torch.empty(())  # tensor trivial pour garder l'API\n",
    "    return f\n",
    "SAMPLE_TEXTS = [\n",
    "    \"In a quiet valley, the river bends slowly around the last farm before the hills.\",\n",
    "    \"Sparse pruning zeroes weights but needs a sparse kernel to speed up compute.\",\n",
    "    \"A small batch size can distort latency because of cache and warmup effects.\",\n",
    "    \"Causal LM perplexity is averaged per token over sliding blocks.\",\n",
    "    \"Version 1.2.0 fixes: stability on CPU, deterministic seeds, better logging.\",\n",
    "    \"“Hello?” — “Hi; can you hear me?” — “Loud and clear.”\",\n",
    "    \"HTTP 429 means rate limiting; use exponential backoff with jitter.\",\n",
    "    \"Compute follows memory: fewer bytes moved often means fewer milliseconds.\",\n",
    "    \"Numbers: 3.14159, 2.71828, 0.57721 show up in odd places.\",\n",
    "    \"Keep the same corpus when comparing Dense vs Masked vs CSR.\",\n",
    "    \"If latency jumps, check power limits, thermal throttling, governors.\",\n",
    "    \"We log mean, median, and p95 latency because tails matter.\",\n",
    "    \"One batch isn’t enough: run multiple iterations with warmup.\",\n",
    "    \"Tiny masking mistakes can create NaNs; clamp logits if needed.\",\n",
    "    \"When in doubt, profile with both synthetic and real inputs.\"\n",
    "]\n",
    "# Optional: virtually increase the size\n",
    "# SAMPLE_TEXTS = SAMPLE_TEXTS * 20\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c3ecb3",
   "metadata": {
    "id": "b9c3ecb3"
   },
   "source": [
    "## 1) Dense baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bf0833b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5bf0833b",
    "outputId": "6b536f68-ca7a-410a-c409-c7593aedf19c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: EleutherAI/pythia-410m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/content/Edu-Sparsify-LLMs/notebooks/../src/eval/csvlog.py:8: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, pd.DataFrame([row])], ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'nonzero': 405333594,\n",
       "  'total': 405334016,\n",
       "  'sparsity': 1.0411166675439176e-06,\n",
       "  'size_mb': 773.11328125},\n",
       " 189.25483576970882,\n",
       " 1233.5267484333297)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, tok, name = load_fresh()\n",
    "stats = params_size_and_sparsity(model)\n",
    "ppl   = eval_ppl_causal(model, tok, SAMPLE_TEXTS, device)\n",
    "lat   = measure_latency_ms(latency_fn(model, tok, gen_tokens=64), 512, 4, warmup=10, iters=30)\n",
    "append_row(CSV_PATH, setup='Dense', size_mb=stats['size_mb'], sparsity=stats['sparsity'], latency_ms=lat, perplexity=ppl)\n",
    "stats, ppl, lat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0098f2",
   "metadata": {
    "id": "de0098f2"
   },
   "source": [
    "## 2) Masked pruning (30%) — dense execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5365922b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5365922b",
    "outputId": "7f3d2d53-d542-4767-b100-86d9a7b866a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: EleutherAI/pythia-410m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'nonzero': 299194207,\n",
       "  'total': 405334016,\n",
       "  'sparsity': 0.2618576403910794,\n",
       "  'size_mb': 773.11328125},\n",
       " 353.49905823886434,\n",
       " 1245.3730822666632)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SP_MASK = 0.30\n",
    "model, tok, name = load_fresh()\n",
    "layers = select_prunable_linears(model, blacklist=(\"lm_head\",))\n",
    "apply_global_magnitude_pruning_cpu_safe(layers, amount=SP_MASK)\n",
    "freeze_pruning_(layers)\n",
    "stats = params_size_and_sparsity(model)\n",
    "ppl   = eval_ppl_causal(model, tok, SAMPLE_TEXTS, device)\n",
    "lat   = measure_latency_ms(latency_fn(model, tok, gen_tokens=64), 512, 4, warmup=10, iters=30)\n",
    "append_row(CSV_PATH, setup=f'Masked{int(SP_MASK*100)}', size_mb=stats['size_mb'], sparsity=stats['sparsity'], latency_ms=lat, perplexity=ppl)\n",
    "stats, ppl, lat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc76a8de",
   "metadata": {
    "id": "dc76a8de"
   },
   "source": [
    "## 3) CSR execution (30%) — real sparse kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41b1330a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "41b1330a",
    "outputId": "b01b2b7b-0e39-4680-c1c5-e5705e8ebb2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: EleutherAI/pythia-410m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/content/Edu-Sparsify-LLMs/notebooks/../src/wrappers/linear_csr.py:16: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at /pytorch/aten/src/ATen/native/TensorShape.cpp:4421.)\n",
      "  out = torch.matmul(W, x.T).T               # [out,b] -> [b,out]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'nonzero': 120350531,\n",
       "  'total': 392741888,\n",
       "  'sparsity': 0.6935632926427242,\n",
       "  'size_mb': 749.095703125},\n",
       " 36856.12814547432,\n",
       " 1355.0688253333342)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SP_CSR = 0.30\n",
    "model, tok, name = load_fresh()\n",
    "layers = select_prunable_linears(model, blacklist=(\"lm_head\",))\n",
    "apply_global_magnitude_pruning_cpu_safe(layers, amount=SP_CSR)\n",
    "freeze_pruning_(layers); convert_linear_weights_to_csr_(layers)\n",
    "swapped = 0\n",
    "def find_parent(root, child):\n",
    "    for _, mod in root.named_modules():\n",
    "        for cn, cc in mod.named_children():\n",
    "            if cc is child: return mod, cn\n",
    "    raise RuntimeError('Parent not found')\n",
    "for lin in layers:\n",
    "    if swapped >= 4: break\n",
    "    parent, attr = find_parent(model, lin)\n",
    "    setattr(parent, attr, LinearCSRForward(lin.weight.detach(), lin.bias.detach() if lin.bias is not None else None).to(device))\n",
    "    swapped += 1\n",
    "stats = params_size_and_sparsity(model)\n",
    "ppl   = eval_ppl_causal(model, tok, SAMPLE_TEXTS, device)\n",
    "lat   = measure_latency_ms(latency_fn(model, tok, gen_tokens=64), 512, 4, warmup=10, iters=30)\n",
    "append_row(CSV_PATH, setup=f'CSR{int(SP_CSR*100)}', size_mb=stats['size_mb'], sparsity=stats['sparsity'], latency_ms=lat, perplexity=ppl)\n",
    "stats, ppl, lat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba329b41",
   "metadata": {
    "id": "ba329b41"
   },
   "source": [
    "## 4) Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "196a989c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 198
    },
    "id": "196a989c",
    "outputId": "c4de0998-5a9f-418e-95ca-f827e3eb5f67"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"df\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"setup\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Dense\",\n          \"Masked30\",\n          \"CSR80\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"size_mb\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 13.866555195751618,\n        \"min\": 749.095703125,\n        \"max\": 773.11328125,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          749.095703125,\n          773.11328125\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sparsity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.35023022083373273,\n        \"min\": 1.0411166675439176e-06,\n        \"max\": 0.6935632926427242,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1.0411166675439176e-06,\n          0.2618576403910794\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"latency_ms\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 67.01488407984016,\n        \"min\": 1233.5267484333297,\n        \"max\": 1355.0688253333342,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1233.5267484333297,\n          1245.3730822666632\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"perplexity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 21122.375595383957,\n        \"min\": 189.2548357697088,\n        \"max\": 36856.12814547432,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          189.2548357697088,\n          353.49905823886434\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "df"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-de62e173-f1df-4d58-81a9-98155b6d158f\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>setup</th>\n",
       "      <th>size_mb</th>\n",
       "      <th>sparsity</th>\n",
       "      <th>latency_ms</th>\n",
       "      <th>perplexity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dense</td>\n",
       "      <td>773.113281</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>1233.526748</td>\n",
       "      <td>189.254836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Masked30</td>\n",
       "      <td>773.113281</td>\n",
       "      <td>0.261858</td>\n",
       "      <td>1245.373082</td>\n",
       "      <td>353.499058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CSR80</td>\n",
       "      <td>749.095703</td>\n",
       "      <td>0.693563</td>\n",
       "      <td>1355.068825</td>\n",
       "      <td>36856.128145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-de62e173-f1df-4d58-81a9-98155b6d158f')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-de62e173-f1df-4d58-81a9-98155b6d158f button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-de62e173-f1df-4d58-81a9-98155b6d158f');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-2d07777a-5d50-40a5-b3ce-f6b0b2f71f5c\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2d07777a-5d50-40a5-b3ce-f6b0b2f71f5c')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-2d07777a-5d50-40a5-b3ce-f6b0b2f71f5c button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "  <div id=\"id_12dd727d-5b2a-4f37-8a40-811c381bab88\">\n",
       "    <style>\n",
       "      .colab-df-generate {\n",
       "        background-color: #E8F0FE;\n",
       "        border: none;\n",
       "        border-radius: 50%;\n",
       "        cursor: pointer;\n",
       "        display: none;\n",
       "        fill: #1967D2;\n",
       "        height: 32px;\n",
       "        padding: 0 0 0 0;\n",
       "        width: 32px;\n",
       "      }\n",
       "\n",
       "      .colab-df-generate:hover {\n",
       "        background-color: #E2EBFA;\n",
       "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "        fill: #174EA6;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate {\n",
       "        background-color: #3B4455;\n",
       "        fill: #D2E3FC;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate:hover {\n",
       "        background-color: #434B5C;\n",
       "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "        fill: #FFFFFF;\n",
       "      }\n",
       "    </style>\n",
       "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
       "            title=\"Generate code using this dataframe.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    <script>\n",
       "      (() => {\n",
       "      const buttonEl =\n",
       "        document.querySelector('#id_12dd727d-5b2a-4f37-8a40-811c381bab88 button.colab-df-generate');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      buttonEl.onclick = () => {\n",
       "        google.colab.notebook.generateWithVariable('df');\n",
       "      }\n",
       "      })();\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "      setup     size_mb  sparsity   latency_ms    perplexity\n",
       "0     Dense  773.113281  0.000001  1233.526748    189.254836\n",
       "1  Masked30  773.113281  0.261858  1245.373082    353.499058\n",
       "2     CSR80  749.095703  0.693563  1355.068825  36856.128145"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ../results/size_vs_sparsity.png\n",
      "Saved: ../results/latency_vs_sparsity.png\n",
      "Saved: ../results/ppl_vs_sparsity.png\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(CSV_PATH); display(df)\n",
    "bar_plot(df, 'setup', 'size_mb', 'Model size (MB)', 'size_vs_sparsity.png', RESULTS_DIR, y_min=700)\n",
    "bar_plot(df, 'setup', 'latency_ms', 'Latency (ms / forward)', 'latency_vs_sparsity.png', RESULTS_DIR)\n",
    "bar_plot(df, 'setup', 'perplexity', 'Perplexity', 'ppl_vs_sparsity.png', RESULTS_DIR)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
